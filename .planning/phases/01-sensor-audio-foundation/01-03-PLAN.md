---
phase: 01-sensor-audio-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-01", "01-02"]
files_modified:
  - src/audio/AudioEngine.ts
  - src/audio/SoundBank.ts
  - src/audio/FeedbackTrigger.ts
  - src/audio/types.ts
  - src/stores/useAudioStore.ts
  - src/hooks/useSensorPipeline.ts
  - src/hooks/useAudioFeedback.ts
  - assets/audio/slosh-light.mp3
  - assets/audio/slosh-medium.mp3
  - assets/audio/slosh-heavy.mp3
  - assets/audio/spill.mp3
  - App.tsx
autonomous: false

must_haves:
  truths:
    - "Water slosh sounds play when spill risk exceeds graduated thresholds"
    - "Splash sound plays when user exceeds spill threshold"
    - "Audio feedback occurs within 100ms of sensor input"
    - "Audio plays correctly alongside music without cutting it off (ducking)"
    - "Cooldown prevents rapid-fire spills after one bad moment"
  artifacts:
    - path: "src/audio/AudioEngine.ts"
      provides: "AudioContext management and buffer playback"
      exports: ["AudioEngine"]
    - path: "src/audio/SoundBank.ts"
      provides: "Pre-loaded audio buffers for instant playback"
      exports: ["SoundBank"]
    - path: "src/audio/FeedbackTrigger.ts"
      provides: "Risk-to-sound mapping with cooldowns"
      exports: ["FeedbackTrigger"]
    - path: "src/hooks/useSensorPipeline.ts"
      provides: "React hook connecting sensor to pipeline"
      exports: ["useSensorPipeline"]
    - path: "src/hooks/useAudioFeedback.ts"
      provides: "React hook triggering audio from risk values"
      exports: ["useAudioFeedback"]
  key_links:
    - from: "src/audio/AudioEngine.ts"
      to: "react-native-audio-api"
      via: "AudioContext.createBufferSource()"
      pattern: "createBufferSource"
    - from: "src/audio/AudioEngine.ts"
      to: "iOS audio session"
      via: "AudioManager.setAudioSessionOptions with duckOthers"
      pattern: "duckOthers"
    - from: "src/audio/FeedbackTrigger.ts"
      to: "src/stores/useSensorStore.ts"
      via: "reads risk value, triggers audio"
      pattern: "risk.*threshold"
    - from: "src/hooks/useAudioFeedback.ts"
      to: "src/audio/FeedbackTrigger.ts"
      via: "trigger.evaluate() on risk changes"
      pattern: "trigger\\.evaluate"
---

<objective>
Implement the audio feedback system and integrate the complete sensor-to-audio pipeline.

Purpose: Complete the core differentiator - real-time audio feedback on rough driving. This is the moment where sensor data becomes actionable feedback that trains muscle memory.

Output: Working app that plays graduated slosh sounds on rough inputs and splash on spill, with proper audio mixing (ducking) and cooldowns. Verified on physical device.
</objective>

<execution_context>
@/Users/papanash/.claude/get-shit-done/workflows/execute-plan.md
@/Users/papanash/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-sensor-audio-foundation/01-CONTEXT.md
@.planning/phases/01-sensor-audio-foundation/01-RESEARCH.md
@.planning/phases/01-sensor-audio-foundation/01-01-SUMMARY.md
@.planning/phases/01-sensor-audio-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement audio engine with preloading and ducking</name>
  <files>
    src/audio/types.ts
    src/audio/AudioEngine.ts
    src/audio/SoundBank.ts
    src/stores/useAudioStore.ts
    assets/audio/slosh-light.mp3
    assets/audio/slosh-medium.mp3
    assets/audio/slosh-heavy.mp3
    assets/audio/spill.mp3
  </files>
  <action>
**Audio Asset Setup:**

Create assets/audio/ directory. Source placeholder audio files:
- Use royalty-free game SFX from freesound.org or similar
- slosh-light.mp3: Gentle water movement (0.5-1s duration)
- slosh-medium.mp3: Moderate water slosh (0.5-1s duration)
- slosh-heavy.mp3: Dramatic water slosh (0.5-1s duration)
- spill.mp3: Dramatic splash/spill sound (1-2s duration)

For initial development, create simple placeholder files if sourcing is blocked. Can be replaced later.
Alternative: Use `expo-av` Audio.Sound to create programmatic test tones if audio files unavailable.

**Implementation:**

Create src/audio/types.ts:
```typescript
export type SoundName = 'slosh-light' | 'slosh-medium' | 'slosh-heavy' | 'spill';

export interface AudioState {
  isInitialized: boolean;
  isInterrupted: boolean;  // Phone call, nav prompt
  volume: number;          // 0-1, independent of system volume
}
```

Create src/audio/SoundBank.ts:
- Map of SoundName to AudioBuffer
- preload() method loads all sounds using expo-asset + decodeAudioDataSource
- get(name: SoundName) returns AudioBuffer or undefined
- Uses require() for asset bundling:
  ```typescript
  const SOUND_ASSETS = {
    'slosh-light': require('@/assets/audio/slosh-light.mp3'),
    // ...
  };
  ```
- See 01-RESEARCH.md "Pre-loaded Audio Buffer Pool" for pattern

Create src/audio/AudioEngine.ts:
- Manages AudioContext lifecycle
- initialize() method:
  1. Configure iOS audio session with ducking:
     ```typescript
     AudioManager.setAudioSessionOptions({
       iosCategory: 'playback',
       iosMode: 'default',
       iosOptions: ['mixWithOthers', 'duckOthers'],
     });
     ```
  2. Enable interruption observation: `AudioManager.observeAudioInterruptions(true)`
  3. Create AudioContext
  4. Call SoundBank.preload()
- play(soundName: SoundName) method:
  - Get buffer from SoundBank
  - Create BufferSource, connect to destination, start immediately
  - Return immediately (fire-and-forget for low latency)
- suspend() and resume() for background handling
- isInterrupted getter (from interruption callbacks)

Create src/stores/useAudioStore.ts:
- State: AudioState from types.ts
- Actions: setInitialized, setInterrupted, setVolume
- Initial state: { isInitialized: false, isInterrupted: false, volume: 1.0 }
  </action>
  <verify>
- `npx tsc --noEmit` passes
- Audio files exist in assets/audio/ (or placeholders noted)
- AudioEngine.initialize() configures iOS session with duckOthers
- SoundBank.preload() loads all 4 sounds
- useAudioStore exports hook with isInitialized, isInterrupted, volume
  </verify>
  <done>
Audio engine complete with pre-loaded buffers for instant playback and iOS audio session configured for ducking (mixing with music without cutoff).
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement feedback trigger and full pipeline integration</name>
  <files>
    src/audio/FeedbackTrigger.ts
    src/hooks/useSensorPipeline.ts
    src/hooks/useAudioFeedback.ts
    App.tsx
  </files>
  <action>
Create src/audio/FeedbackTrigger.ts:
- Maps risk value to sound selection (from 01-RESEARCH.md Pattern 3):
  - risk < 0.3: null (silence = smooth driving)
  - risk 0.3-0.5: 'slosh-light'
  - risk 0.5-0.7: 'slosh-medium'
  - risk >= 0.7: 'slosh-heavy'
  - isSpill: 'spill' (overrides risk-based selection)
- Implements SpillCooldown (from 01-CONTEXT.md: ~2-3 seconds):
  - canTriggerSpill(): boolean
  - startCooldown(): void
  - Use 2500ms cooldown (Claude's discretion: middle of 2-3s range)
- evaluate(risk: number, isSpill: boolean) returns SoundName | null
- Tracks last played sound to avoid rapid repeats of same sound

Create src/hooks/useSensorPipeline.ts:
- React hook that:
  1. Creates DeviceMotionManager and SensorPipeline instances
  2. Subscribes to sensor events on mount
  3. Processes events through pipeline
  4. Updates useSensorStore with risk/isSpill
  5. Cleans up subscription on unmount
- Handles settling period (1500ms delay before feedback enabled)
- Returns { isActive, isSettling, start, stop }

Create src/hooks/useAudioFeedback.ts:
- React hook that:
  1. Subscribes to useSensorStore risk changes
  2. Uses FeedbackTrigger to determine sound
  3. Calls AudioEngine.play() when sound is triggered
  4. Respects isInterrupted (no feedback during calls)
  5. Respects isSettling (no feedback during calibration)
- Uses useEffect with risk dependency
- Minimal re-renders - only trigger on threshold crossings

Update App.tsx to integrate full pipeline:
```typescript
function App() {
  const [isReady, setIsReady] = useState(false);

  useEffect(() => {
    async function init() {
      await AudioEngine.initialize();
      setIsReady(true);
    }
    init();
  }, []);

  if (!isReady) {
    return <LoadingScreen />;  // Simple "Loading..." text
  }

  return <MainScreen />;
}

function MainScreen() {
  const { isActive, isSettling, start, stop } = useSensorPipeline();
  useAudioFeedback();  // Triggers audio based on risk

  // Simple debug UI showing:
  // - Start/Stop button
  // - isSettling indicator
  // - Current risk value
  // - Last triggered sound
  return (
    <View style={styles.container}>
      <Text>Water Cup Coach - Debug</Text>
      <Button title={isActive ? "Stop" : "Start"} onPress={isActive ? stop : start} />
      <Text>Settling: {isSettling ? "Yes" : "No"}</Text>
      <RiskDisplay />  {/* Shows current risk from store */}
    </View>
  );
}
```

Run prebuild to generate native projects:
```bash
npx expo prebuild
```

This is required for react-native-audio-api which is a native module.
  </action>
  <verify>
- `npx tsc --noEmit` passes
- FeedbackTrigger has 2500ms cooldown
- useSensorPipeline handles start/stop/settling
- useAudioFeedback triggers sounds on risk threshold crossings
- App.tsx initializes audio engine before rendering main content
- `npx expo prebuild` completes successfully
  </verify>
  <done>
Full sensor-to-audio pipeline integrated: sensor events flow through filter -> jerk -> risk -> audio trigger. App ready for device testing.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify complete pipeline on physical device</name>
  <what-built>
Complete sensor-to-audio feedback pipeline:
- DeviceMotion streams at 50Hz with gravity compensation
- Low-pass filter removes vibration noise
- Jerk calculation with actual timestamps
- Risk normalization with graduated thresholds
- Rolling window smoothing
- Pre-loaded audio for instant playback
- iOS audio ducking (mixes with music)
- Settling period and spill cooldown
  </what-built>
  <how-to-verify>
1. Build and run on physical device:
   ```bash
   # iOS
   npx expo run:ios --device

   # Android
   npx expo run:android --device
   ```

2. **Sensor validation:**
   - Open app, tap Start
   - Wait for "Settling: No" (1.5 seconds)
   - Observe risk value updates in debug UI
   - Move phone sharply - risk should increase
   - Hold phone still - risk should return to 0

3. **Audio validation:**
   - Play music in background (Spotify, etc.)
   - Move phone with varying intensity:
     - Gentle movement: light slosh sound
     - Moderate movement: medium slosh
     - Sharp movement: heavy slosh
     - Very sharp: spill sound
   - Music should duck (get quieter) when sounds play, then restore
   - After spill, wait 2.5 seconds before another spill can trigger

4. **Latency validation:**
   - Sharp phone movement should produce audio within ~100ms
   - Should feel responsive, not delayed

5. **Edge cases:**
   - Receive phone call while running - feedback should pause
   - Kill and restart app - should reinitialize cleanly
  </how-to-verify>
  <resume-signal>
Type "approved" if all verifications pass.
If issues, describe: which test failed, what happened vs expected.
  </resume-signal>
</task>

</tasks>

<verification>
Phase 1 success criteria from ROADMAP.md:

1. [ ] Accelerometer and gyroscope data streams at validated 50Hz on both iOS and Android
2. [ ] Water slosh sounds play when user accelerates, brakes, or corners abruptly
3. [ ] Splash sound plays when user exceeds spill threshold
4. [ ] Audio feedback occurs within 100ms of sensor input (measured subjectively)
5. [ ] Audio plays correctly alongside music or podcasts without cutting them off

Requirements coverage:
- SENS-01: Accelerometer at 50Hz (via DeviceMotion)
- SENS-02: Gyroscope (rotationRate from DeviceMotion - available but not actively used in Phase 1)
- SENS-04: Low-pass filter (LowPassFilter with 2Hz cutoff)
- SENS-05: Gravity compensation (DeviceMotion.acceleration is pre-compensated)
- SMTH-01: Jerk calculation (JerkCalculator per axis)
- SMTH-02: Combined jerk RMS (magnitude in JerkCalculator)
- SMTH-03: Spill risk normalization (SpillRiskNormalizer 0-1)
- SMTH-04: Rolling window (RollingWindow 500ms)
- AUDI-01: Water slosh on threshold (FeedbackTrigger graduated sounds)
- AUDI-02: Splash on spill (FeedbackTrigger isSpill handling)
- AUDI-04: Sub-100ms latency (pre-loaded buffers, synchronous pipeline)
- AUDI-05: Audio ducking (iOS duckOthers option)
</verification>

<success_criteria>
- Audio engine initializes with pre-loaded buffers
- iOS audio session configured for ducking (mixWithOthers + duckOthers)
- FeedbackTrigger maps risk to graduated sounds with 2.5s spill cooldown
- Full pipeline wired: sensor -> filter -> jerk -> risk -> audio
- Physical device testing confirms:
  - Sensor data streaming at ~50Hz
  - Audio plays within perceptible 100ms of movement
  - Music ducks instead of cutting off
  - Cooldown prevents rapid spills
</success_criteria>

<output>
After completion, create `.planning/phases/01-sensor-audio-foundation/01-03-SUMMARY.md`
</output>
